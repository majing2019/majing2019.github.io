<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Separable Convolution</title>
    <url>/2020/02/06/Separable-Convolution/</url>
    <content><![CDATA[<p>阅读论文《The Evolved Transformer》时遇到了separable convolution的概念，因此找了相关资料学习了一下。</p>
<blockquote>
<p>参考：<br><a href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-al" target="_blank" rel="noopener">https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-al</a></p>
</blockquote>
<a id="more"></a>
<p>在讲Separable Convolution前先了解下常用的卷积网络的定义。</p>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><blockquote>
<p>参考：<br><a href="https://towardsdatascience.com/what-is-a-neural-network-6010edabde2b" target="_blank" rel="noopener">https://towardsdatascience.com/what-is-a-neural-network-6010edabde2b</a></p>
</blockquote>
<p>卷积网络中最重要的是卷积核，通过卷积核在图像每个区域的运算，得到图像不同的特征，如下图（可以在<a href="http://setosa.io/ev/image-kernels/" target="_blank" rel="noopener">http://setosa.io/ev/image-kernels/</a>中更好得体验）：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc1.png?e=1580955169&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:y2r-foEXvLreIRvdTfPoxbFPLMI=&amp;attname=" alt="图片"></p>
<p>上面这张图使用outliine卷积核，实际中可以使用sharp等不同功能的卷积核以达到不同效果。</p>
<p>对于神经网络的每一层而言，可以使用多个卷积和得到不同的特征图，并将这些特征图一起输入到下一层网络。最终这些特征供给最后一层的分类器进行匹配，得到分类结果。下面的动画展示了这个过程：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/cnn1.gif?e=1580955292&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:fsQbcGd9VpumSiAnt9aR8Y4HVbg=&amp;attname=" alt="图片"></p>
<p><img src="http://q503tsu73.bkt.clouddn.com/cnn2.gif?e=1580955575&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:4Rtb7WOCo1E4quaE2SaMqNfDGVE=&amp;attname=" alt="图片"></p>
<p><img src="http://q503tsu73.bkt.clouddn.com/cnn3.gif?e=1580955765&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:qRuKKXxDa7pb0JoiO7F21H6itbU=&amp;attname=" alt="图片"></p>
<p><img src="http://q503tsu73.bkt.clouddn.com/cnn4.gif?e=1580956282&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:dKMmJXyxzhhTLIdF894TsINrO2s=&amp;attname=" alt="图片"></p>
<p>Separable Convolution可以分成spatial separable convolution和depthwise separable convolution。</p>
<p>对于12x12x3的图像，5x5x3的卷积核，能产生8x8x1的输出：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc3.png?e=1580956348&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:4jAs9Yfkbmd8FuQzbX0v4Z6TXhs=&amp;attname=" alt="图片"></p>
<p>假设我们想要8x8x256的输出，则需要使用256个卷积核来创造256个8x8x1的图像，把他们叠加在一起产生8x8x256的输出：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc4.png?e=1580956393&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:KM1HZWVpRIc8VwD9YFMrPDBktFk=&amp;attname=" alt="图片"></p>
<p>即12x12x3 — (5x5x3x256) — &gt;12x12x256</p>
<h2 id="Spatial-Separable-Convolutions"><a href="#Spatial-Separable-Convolutions" class="headerlink" title="Spatial Separable Convolutions"></a>Spatial Separable Convolutions</h2><p>Spatial separable convolution将卷积分成两部分，最常见的是把3x3的kernel分解成3x1和1x3的kernel，如：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc5.png?e=1580956800&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:bdOSf4gz5XRdRVT3oUn7EWnvpZ0=&amp;attname=" alt="图片"></p>
<p>通过这种方式，原本一次卷积要算9次乘法，现在只需要6次。</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc6.png?e=1580956475&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:UHt9gX6zrKk2Y8O_j6f6Bh6916o=&amp;attname=" alt="图片"></p>
<p>还有一个Sobel kernel（用来检测边）也是用的这种方法：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc7.png?e=1580956800&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:TFzY3Ed_11LbgKJL34bhIqcxIyg=&amp;attname=" alt="图片"></p>
<p>但spatial separable convolution存在的问题是，不是所有kernel都能转换成2个小的kernel。</p>
<h2 id="Depthwise-Separable-Convolutions"><a href="#Depthwise-Separable-Convolutions" class="headerlink" title="Depthwise Separable Convolutions"></a>Depthwise Separable Convolutions</h2><p>由于卷积并不使用矩阵相乘，为了减少计算量，可以将卷积的过程分成两部分：a depthwise convolution and a pointwise convolution. </p>
<h3 id="depthwise-convolution"><a href="#depthwise-convolution" class="headerlink" title="depthwise convolution"></a>depthwise convolution</h3><p>首先，我们使用3个5x5x1的卷积核产生8x8x3的图像：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc2.png?e=1580956557&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:09oVR6LIhWN293RMDFzOV66LG5A=&amp;attname=" alt="图片"></p>
<h3 id="pointwise-convolution"><a href="#pointwise-convolution" class="headerlink" title="pointwise convolution"></a>pointwise convolution</h3><p>其次，使用1x1x3 的卷积核对每个像素计算，得到8x8x1 的图像：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc8.png?e=1580956603&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:BxS4Xqtt2YsqJ5GJVFVlnK9D3xw=&amp;attname=" alt="图片"></p>
<p>使用256个1x1x3 的卷积核，则恶意产生8x8x256的图像：</p>
<p><img src="http://q503tsu73.bkt.clouddn.com/sc9.png?e=1580956633&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:vVbqfesu_9oG3fHhINDk9pA7__U=&amp;attname=" alt="图片"></p>
<p>可以看到，整个过程由原来的12x12x3 — (5x5x3x256) →12x12x256，变成12x12x3 — (5x5x1x1) — &gt; (1x1x3x256) — &gt;12x12x256</p>
<h2 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h2><p>主要就是减少了计算量，原先是256个5x5x3的卷积核移动8x8次，即需要256x3x5x5x8x8=1,228,800次乘法计算。使用depthwise convolution，有3个5x5x1的卷积核移动8x8次，需要3x5x5x8x8 = 4,800次乘法计算。使用pointwise convolution，有256个1x1x3的卷积核移动8x8次，需要256x1x1x3x8x8=49,152次乘法计算，加起来共有53,952次计算。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul>
<li>keras doc：<a href="https://keras.io/layers/convolutional/" target="_blank" rel="noopener">https://keras.io/layers/convolutional/</a></li>
<li><a href="https://github.com/alexandrosstergiou/keras-DepthwiseConv3D" target="_blank" rel="noopener">https://github.com/alexandrosstergiou/keras-DepthwiseConv3D</a></li>
<li>[<a href="https://github.com/sara-kassani/Depthwise-Separable-Convolutional-Neural-Network-for-Skin-Lesion-Classification](" target="_blank" rel="noopener">https://github.com/sara-kassani/Depthwise-Separable-Convolutional-Neural-Network-for-Skin-Lesion-Classification](</a></li>
</ul>
]]></content>
      <tags>
        <tag>Convolution</tag>
        <tag>卷积网络</tag>
      </tags>
  </entry>
  <entry>
    <title>论文粗读——《The Evolved Transformer》</title>
    <url>/2020/02/05/%E8%AE%BA%E6%96%87%E7%B2%97%E8%AF%BB%E2%80%94%E2%80%94%E3%80%8AThe-Evolved-Transformer%E3%80%8B/</url>
    <content><![CDATA[<p>今天阅读了论文《The Evolved Transformer》，该论文使用了神经架构搜索方法找到了一个更优的transformer结构。下面是阅读过程中的笔记。</p>
<a id="more"></a>
<blockquote>
<p>参考：<br><a href="https://arxiv.org/pdf/1901.11117.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1901.11117.pdf</a><br><a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/evolved_transformer.py" target="_blank" rel="noopener">https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/evolved_transformer.py</a><br><a href="https://blog.csdn.net/jasonzhoujx/article/details/88875469" target="_blank" rel="noopener">https://blog.csdn.net/jasonzhoujx/article/details/88875469</a></p>
</blockquote>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><ul>
<li>神经架构搜索<ul>
<li>tournament selection architecture search </li>
<li>warm start</li>
<li>Progressive Dynamic Hurdles（PDH）</li>
</ul>
</li>
<li>搜索出了一个新的transformer架构：Evolved Transformer</li>
</ul>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="搜索空间"><a href="#搜索空间" class="headerlink" title="搜索空间"></a>搜索空间</h3><ul>
<li>encoder stackable cell<ul>
<li>6个NASNet-style block<ul>
<li>左右两个block将输入的hidden state转成左右两个hidden state再归并成为一个新的hidden state，作为self-attention的输入</li>
</ul>
</li>
</ul>
</li>
<li>decoder stackable cell<ul>
<li>8个NASNet-style block</li>
</ul>
</li>
</ul>
<p><img src="http://q503tsu73.bkt.clouddn.com/et-transformer.png?e=1580892803&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:ln2axf1iGaz9DI2q6j1kLn1lAx8=&amp;attname=" alt="图片"></p>
<ul>
<li>搜索空间branch<ul>
<li>Input：分支可以从输入池中选择一个隐藏状态作为当前block的输入。单元中的第i个block可以从[0, i]个隐藏状态中进行选择，其中第j个隐藏状态表示该cell中第j个block的输出，第0个候选项为单元的输入。</li>
<li>Normalization：归一化项提供了两个选项， [LAYER NORMALIZATION (Ba et al., 2016), NONE]</li>
<li>Layer：构造一个神经网络层，提供的选项包括：<ul>
<li>标准卷积</li>
<li>深度可分离卷积</li>
<li>LIGHTWEIGHT 卷积</li>
<li>n头注意力层</li>
<li>GATED LINEAR UNIT</li>
<li>ATTEND TO ENCODER（decoder专用）</li>
<li>全等无操作</li>
<li>Dead Branch，切断输出</li>
</ul>
</li>
<li>Relative Output Dimension：决定神经网络层输出的维度。</li>
<li>Activation：搜索中激活函数的选项有[SWISH, RELU, LEAKY RELU, NON]</li>
<li>Combiner Function：表征的是左枝和右枝的结合方式，包括{ADDITION、CONCATENATION、MULTIPLICATION}。如果左右枝最终输出形状不同，则需要使用padding进行填充。短的向量向长的向量对齐，当使用加法进行结合时使用0填充，当使用乘法进行结合时使用1填充。</li>
<li>Number of cells：纵向叠加的cell的数量，搜索范围是[1,6]</li>
</ul>
</li>
</ul>
<h3 id="演进过程"><a href="#演进过程" class="headerlink" title="演进过程"></a>演进过程</h3><ul>
<li>锦标赛选择（Tournament Selection）：<ul>
<li>tournament selection算法是一种遗传算法，首先随机生成一批个体, 这些个体是一个个由不同组件组成的完整的模型，我们在目标任务上训练这些个体并在验证集上面计算他们的表现。</li>
<li>首先在初始种群中进行采样产生子种群，从子种群中选出适应性（fitness）最高的个体作为亲本（parent）。被选中的亲本进行突变——也就是将网络模型中的一些组件改变为其他的组件——以产生子模型，然后在对这些子模型分配适应度（fitness），在训练集和测试集上进行训练和验证。</li>
<li>对种群重新进行采样，用通过评估的子模型代替子种群中的fitness的个体以生成新的种群。</li>
<li>重复上面的步骤，直到种群中出现超过给定指标的模型。</li>
</ul>
</li>
<li>渐进式动态障碍（Progressive Dynamic Hurdle）：<ul>
<li>实验使用的训练集是WMT14英语到德语的机器翻译数据集，完整的训练和验证过程需要很长的时间，如果在所有的子模型上进行完整的训练和验证过程将会耗费很大的计算资源。因此论文中使用渐进式动态障碍的方法来提前停止一些没有前景的模型的训练，转而将更多的计算资源分配那些当前表现更好的子模型。具体来说就是让当前表现最好的一些模型多训练一些step。</li>
<li>假设当前种群经过一次锦标赛选择，生成了m个子模型并且加入到了种群中，这时候计算整个种群fitness的平均值h0，下一次锦标赛选择将会以h0作为对照，生成的另外m个fitness超过h0的子模型可以继续训练s1个step，接着进行种群中的所有的其他个体会继续训练s1个step，然后在新的种群中生成h1，以此类推知道种群中所有的个体的训练step都达到一个指定值。</li>
<li>如果一个子模型是由第iii次锦标赛选择之后的亲本生成的，那么验证的过程将会进行iii次。第一次为该模型分配s0次的训练step并且在验证集上进行验证，若验证的fitness大于h0则再分配s1次训练step，再验证，再与h1比较，只有子样本通过h0,h1,…,hi次比较才能作为新的个体加入到新的种群中。</li>
</ul>
</li>
</ul>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul>
<li><p>机器翻译</p>
<ul>
<li>在初始的10K step使用0.01的learning rate</li>
<li><p>Transformer</p>
<ul>
<li>inverse-square-root decay to 0 at 300K steps：$l r=s t e p^{-0.00303926^{\circ}}-.962392$</li>
</ul>
</li>
<li><p>Evolved Transformer</p>
<ul>
<li>single-cycle cosine decay</li>
</ul>
</li>
<li>every decay was paired with the same constant 0.01 warmup.</li>
<li>大模型使用高一点的dropout（0.3），小模型使用0.2 dropout</li>
<li>beam-size=6, lenth-penalty=0.6, max-output=50</li>
</ul>
</li>
<li>语言模型<ul>
<li>跟机器翻译差不多，去掉了label smooth, intra-attention dropout=0.0</li>
</ul>
</li>
<li>Search Configuration<ul>
<li>populatino=100</li>
<li>mutation=2.5%</li>
<li>fitness: negative log perplexity</li>
</ul>
</li>
</ul>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><ul>
<li>最终搜索出来的模型结构</li>
</ul>
<p><img src="http://q503tsu73.bkt.clouddn.com/et-transformer2.png?e=1580893009&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:aAFv3BbiOEmd1YLT9aabOYCYURE=&amp;attname=" alt="图片"></p>
<ul>
<li>embedding_size=768, 6 encoder, 6 decoder</li>
<li>attention_head=16</li>
<li>ET比Transformer可以在更小的模型上达到更好的效果，当模型增大时两者的差距就不大了（可能因为模型越大越容易过拟合，而且单独增加embedding_size可能不起作用，需要和depth共同增加）</li>
</ul>
]]></content>
      <tags>
        <tag>Transformer</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读——《Towards a Human-like Open-Domain Chatbot》</title>
    <url>/2020/02/04/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E2%80%94%E2%80%94%E3%80%8ATowards-a-Human-like-Open-Domain-Chatbot%E3%80%8B/</url>
    <content><![CDATA[<p>今天阅读了谷歌最新出的一篇论文，《Towards a Human-like Open-Domain Chatbot》，主要提出了端到端对话机器人的一种评测方法和模型框架。下面是阅读过程中的笔记。</p>
<a id="more"></a>
<blockquote>
<p>参考：<br><a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" target="_blank" rel="noopener">https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html</a><br><a href="https://arxiv.org/pdf/2001.09977.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/2001.09977.pdf</a><br><a href="https://github.com/google-research/google-research/tree/master/meena" target="_blank" rel="noopener">https://github.com/google-research/google-research/tree/master/meena</a></p>
</blockquote>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="开放的chatbot-API总结"><a href="#开放的chatbot-API总结" class="headerlink" title="开放的chatbot API总结"></a>开放的chatbot API总结</h3><ul>
<li>cleverbot API: <a href="https://www.cleverbot.com/api/" target="_blank" rel="noopener">https://www.cleverbot.com/api/</a><ul>
<li><a href="https://github.com/plasticuproject/cleverbotfree" target="_blank" rel="noopener">https://github.com/plasticuproject/cleverbotfree</a></li>
</ul>
</li>
<li>xiaobing: <a href="https://www.msxiaobing.com/" target="_blank" rel="noopener">https://www.msxiaobing.com/</a></li>
<li>mitsuku: <a href="https://www.pandorabots.com/mitsuku/" target="_blank" rel="noopener">https://www.pandorabots.com/mitsuku/</a><ul>
<li><a href="https://github.com/hanwenzhu/mitsuku-api" target="_blank" rel="noopener">https://github.com/hanwenzhu/mitsuku-api</a></li>
</ul>
</li>
</ul>
<h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><ul>
<li>模型架构：Evolved Transformer<ul>
<li>模型输入：多轮对话（最多7轮）</li>
<li>模型输出：回复</li>
<li>最佳模型：2.6B参数，10.2PPL，8K BPE subword vocabulary, 训练数据40B words</li>
</ul>
</li>
<li>评测指标<ul>
<li>PPL</li>
<li>SSA（Sensibleness and Specificity Average）用来评估<ul>
<li>whether make sense</li>
<li>whether specific</li>
</ul>
</li>
<li>人工评测使用static（1477个多轮对话）和interactive（想说啥就说啥）两种数据集，发现SSA和PPL在这两个数据集上高度相关</li>
<li>模型在评测集的表现：<ul>
<li>0.72的SSA</li>
<li>经过filtering mechanism 和 tuned decoding后有0.79的SSA，相比于人提供的0.86SSA的回复已经很接近了</li>
</ul>
</li>
</ul>
</li>
<li>方法的局限性<ul>
<li>评测数据集的局限性，不能解决所有领域的问题</li>
</ul>
</li>
</ul>
<h2 id="对话机器人的评价"><a href="#对话机器人的评价" class="headerlink" title="对话机器人的评价"></a>对话机器人的评价</h2><h3 id="人工进行评测时的参考标准"><a href="#人工进行评测时的参考标准" class="headerlink" title="人工进行评测时的参考标准"></a>人工进行评测时的参考标准</h3><ul>
<li>Sensibleness<ul>
<li>common sense</li>
<li>logical coherence</li>
<li>consistency</li>
<li>人工评测时对于可打的标签：confusing, illogical, out of context, factually wrong, make sense</li>
<li>缺陷：对于安全的回答，如I don’t know，无法区分</li>
</ul>
</li>
<li>Specificity<ul>
<li>A: I love tennis.   B: That’s nice 应该被标记为not specific，如果 B：Me too, I can’t get enough of Roger Federer!则被标记为specific</li>
<li>已经被标记为not sensible的直接标记为not specific</li>
</ul>
</li>
<li>SSA<ul>
<li>可以使用Sensibleness和Specificity标记在所有responses的比例来作为参考标准</li>
<li>使用SSA将Sensibleness和Specificity的比例进行了结合</li>
</ul>
</li>
</ul>
<h3 id="可进行对比的几个开源chatbot框架"><a href="#可进行对比的几个开源chatbot框架" class="headerlink" title="可进行对比的几个开源chatbot框架"></a>可进行对比的几个开源chatbot框架</h3><ul>
<li>基于RNN：<a href="https://github.com/lukalabs/cakechat" target="_blank" rel="noopener">https://github.com/lukalabs/cakechat</a></li>
<li>基于Transformer: <a href="https://github.com/microsoft/DialoGPT" target="_blank" rel="noopener">https://github.com/microsoft/DialoGPT</a><ul>
<li>762M参数的模型效果更好一些</li>
<li>dialogpt没有公开其解码和MMI-reranking的过程，gpt2bot实现了解码：<a href="https://github.com/polakowo/gpt2bot" target="_blank" rel="noopener">https://github.com/polakowo/gpt2bot</a></li>
<li>附加一个中文的基于DialoGPT开发的闲聊模型<ul>
<li><a href="https://github.com/yangjianxin1/GPT2-chitchat" target="_blank" rel="noopener">https://github.com/yangjianxin1/GPT2-chitchat</a></li>
<li><a href="https://blog.csdn.net/kingsonyoung/article/details/103803067" target="_blank" rel="noopener">https://blog.csdn.net/kingsonyoung/article/details/103803067</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="构建静态评测集"><a href="#构建静态评测集" class="headerlink" title="构建静态评测集"></a>构建静态评测集</h3><ul>
<li>从单轮开始：<a href="http://ai.stanford.edu/~quocle/QAresults.pdf" target="_blank" rel="noopener">http://ai.stanford.edu/~quocle/QAresults.pdf</a></li>
<li>增加一些个性化问题，如：Do you like cats?<ul>
<li>A: Do you like movies?; B: Yeah. I like sci-fi mostly; A: Really? Which is your favorite?期待I love Back to the Future这样的回答，对于I don’t like movies这样的回复应标记为not sensible</li>
</ul>
</li>
</ul>
<h3 id="进行动态评测"><a href="#进行动态评测" class="headerlink" title="进行动态评测"></a>进行动态评测</h3><ul>
<li>机器人以Hi开始，评测人员自由与bot对话，并对每一个bot的回复进行评测。每一个对话至少14轮，至多28轮。</li>
</ul>
<h2 id="Meena-Chatbot"><a href="#Meena-Chatbot" class="headerlink" title="Meena Chatbot"></a>Meena Chatbot</h2><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><ul>
<li>来源于public social media</li>
<li>清洗流程<ul>
<li>去掉 subword 数目&lt;=2 或 subword 数目 &gt;= 128</li>
<li>去掉 字母比例&lt;0.7</li>
<li>去掉 包含URL</li>
<li>去掉 作者名字bot</li>
<li>去掉 出现100次以上</li>
<li>去掉 跟上文n-gram重复比例过高</li>
<li>去掉 敏感句子</li>
<li>去掉 括号中内容</li>
<li>当一个句子被删除时，则上文全部被删除</li>
</ul>
</li>
<li>共清洗出867M的(context, response)对</li>
<li>使用sentence piece进行BPE分词，得到8K的BPE vocab</li>
<li>最终语料包含341GB的语料(40B word)</li>
</ul>
<h3 id="模型框架"><a href="#模型框架" class="headerlink" title="模型框架"></a>模型框架</h3><ul>
<li>Evolved Transformer<ul>
<li>2.6B parameter</li>
<li>1 ET encoder + 13 ET decoder</li>
</ul>
</li>
<li>最大的模型可达到10.2的PPL</li>
<li>最大的传统Transformer模型（32层decoder）可达到10.7的PPL</li>
<li>hidden size: 2560</li>
<li>attention head: 32</li>
<li>共享编码、解码、softmax的embedding</li>
<li>编码、解码最长是128</li>
</ul>
<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><ul>
<li>使用Adafactor optimizer，初始学习率0.01，在前10k step保持不变，使用inverse square root of the number of steps进行衰减</li>
<li>使用<a href="https://github.com/tensorflow/" target="_blank" rel="noopener">https://github.com/tensorflow/</a>tensor2tensor代码进行训练</li>
</ul>
<h3 id="解码细节"><a href="#解码细节" class="headerlink" title="解码细节"></a>解码细节</h3><ul>
<li><p>为了避免产生乏味的回复，可以使用多种方法进行解码</p>
<ul>
<li>reranking</li>
<li>基于profiles, topics, and styles</li>
<li>强化学习</li>
<li>变分自编吗</li>
</ul>
</li>
<li><p>当PPL足够小时，可以使用sample-and-rank策略进行解码</p>
<ul>
<li><p>使用temperature T随机产生N个独立的候选</p>
<ul>
<li><p>$p_{i}=\frac{\exp \left(z_{i} / T\right)}{\sum_{j} \exp \left(z_{j} / T\right)}$</p>
</li>
<li><p>T=1产生不经过修正的分布</p>
</li>
<li><p>T越大，越容易产生不常见的词，如相关的实体名词，但可能产生错误的词</p>
</li>
<li><p>T越小，越容易产生常见的词，如冠词或介词，虽然安全但不specific</p>
</li>
<li><p>解释1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">温度是神经网络的超参数，用于在应用softmax之前通过缩放对数来控制预测的随机性。 例如，在TensorFlow的LSTM中，温度代表在计算softmax之前将logit除以多少。</span><br><span class="line"></span><br><span class="line">当温度为1时，我们直接在logits（较早层的未缩放输出）上计算softmax，并使用温度为0.6的模型在logits&#x2F;0.6上计算softmax，从而得出较大的值。 在更大的值上执行softmax可使LSTM 更加自信 （需要较少的输入来激活输出层），但在其样本中也更加保守 （从不太可能的候选样本中进行抽样的可能性较小）。 使用较高的温度会在各个类上产生较软的概率分布，并使RNN更容易被样本“激发”，从而导致更多的多样性和更多的错误 。</span><br><span class="line"></span><br><span class="line">softmax函数通过确保网络输出在每个时间步长都在零到一之间，基于其指数值对候选网络的每次迭代进行归一化。</span><br><span class="line"></span><br><span class="line">因此，温度增加了对低概率候选者的敏感性。</span><br></pre></td></tr></table></figure>
</li>
<li><p>解释2</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当T很大时，即趋于正无穷时，所有的激活值对应的激活概率趋近于相同（激活概率差异性较小）；而当T很低时，即趋于0时，不同的激活值对应的激活概率差异也就越大。</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>发现使用beam-search解码会产生重复且无趣的回复，使用sample-and-rank产生的回复会丰富一些</p>
</li>
<li>使用N=20，T=0.88</li>
<li>response score的计算：logP/T，P是response的likelihood，T是token的个数</li>
<li>解码时增加detect cross turn repetitions<ul>
<li>当两个turn的n-gram重复超过一定比例时，则从候选中删除</li>
</ul>
</li>
<li>增加一个分类层，用来过滤掉敏感回复</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="SSA和PPL是相关的"><a href="#SSA和PPL是相关的" class="headerlink" title="SSA和PPL是相关的"></a>SSA和PPL是相关的</h3><ul>
<li>基本呈线性关系</li>
</ul>
<p><img src="http://q503tsu73.bkt.clouddn.com/paper_ssa.png?e=1580825793&amp;token=05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:XYKxV0-Vy99TsjbuB7EorIolYVk=&amp;attname=" alt="图片"></p>
<h3 id="效果的比较"><a href="#效果的比较" class="headerlink" title="效果的比较"></a>效果的比较</h3><ul>
<li>小冰：呈现出个性化的回复，但有时也会无意义，且经常回复得太平常。小冰另一个特点就是具有同情心，可以在以后的评价指标中考虑这一点。小冰有near-human-level engagingness但not very close to human-level humanness，因此在我们的评测指标上SSA不高。</li>
<li>mitsuku：56%SSA（72%sensibility 40%specifity）, 网站上的对话并不是它参加图灵测试的版本</li>
<li>DialoGPT：48%SSA（57%sensibility 49%specifity）</li>
<li>CleverBot：在interactive评测表现比static上稍微好一些（56% interactive SSA，44% static SSA）。发现cleverbot更擅长将话题引入到它更擅长的领域中，缺少personality</li>
<li>Meena：base（72% SSA），full（79% SSA）</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>Chatbot</tag>
      </tags>
  </entry>
  <entry>
    <title>各类资源定期汇总</title>
    <url>/2020/02/01/%E5%90%84%E7%B1%BB%E8%B5%84%E6%BA%90%E5%AE%9A%E6%9C%9F%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<p>一些学习等资源的总结，不定期更新。</p>
<a id="more"></a>
<h1 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h1><h2 id="视频类资源"><a href="#视频类资源" class="headerlink" title="视频类资源"></a>视频类资源</h2><h3 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h3><ul>
<li>吴恩达机器学习：<a href="https://study.163.com/course/courseMain.htm?courseId=1004570029" target="_blank" rel="noopener">https://study.163.com/course/courseMain.htm?courseId=1004570029</a></li>
<li>统计学习基础：链接: <a href="https://pan.baidu.com/s/1NWE6lEJrSgOFAEVVOW2TmQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1NWE6lEJrSgOFAEVVOW2TmQ</a> 提取码: g7km</li>
<li>林轩田机器学习：<a href="https://www.tinymind.cn/articles/168" target="_blank" rel="noopener">https://www.tinymind.cn/articles/168</a></li>
</ul>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><ul>
<li>花书：<a href="https://www.bilibili.com/video/av69236102?from=search&amp;seid=4183604428283884229" target="_blank" rel="noopener">https://www.bilibili.com/video/av69236102?from=search&amp;seid=4183604428283884229</a></li>
</ul>
<h3 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h3><ul>
<li>斯坦福自然语言处理：<a href="https://zhuanlan.zhihu.com/p/63199665" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63199665</a></li>
<li>宗成庆统计自然语言处理：<ul>
<li><a href="https://space.bilibili.com/373951238" target="_blank" rel="noopener">https://space.bilibili.com/373951238</a></li>
<li><a href="https://space.bilibili.com/303667813/video" target="_blank" rel="noopener">https://space.bilibili.com/303667813/video</a></li>
</ul>
</li>
</ul>
<h2 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h2><ul>
<li>CS231n计算机视觉：<a href="https://www.bilibili.com/video/av77752864/" target="_blank" rel="noopener">https://www.bilibili.com/video/av77752864/</a></li>
</ul>
<h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><ul>
<li>David Silver强化学习：<a href="https://space.bilibili.com/74997410?spm_id_from=333.788.b_765f7570696e666f.2" target="_blank" rel="noopener">https://space.bilibili.com/74997410?spm_id_from=333.788.b_765f7570696e666f.2</a></li>
</ul>
<h2 id="博客类资源"><a href="#博客类资源" class="headerlink" title="博客类资源"></a>博客类资源</h2><ul>
<li>科学空间：<a href="https://kexue.fm/" target="_blank" rel="noopener">https://kexue.fm/</a></li>
</ul>
<h2 id="学习笔记类资源"><a href="#学习笔记类资源" class="headerlink" title="学习笔记类资源"></a>学习笔记类资源</h2><h3 id="机器学习-1"><a href="#机器学习-1" class="headerlink" title="机器学习"></a>机器学习</h3><ul>
<li>吴恩达机器学习笔记：<a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes" target="_blank" rel="noopener">https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes</a></li>
<li>统计学习基础笔记：<a href="https://github.com/SmirkCao/Lihang" target="_blank" rel="noopener">https://github.com/SmirkCao/Lihang</a></li>
<li>百面机器学习：<a href="https://github.com/Relph1119/QuestForMachineLearning-Camp" target="_blank" rel="noopener">https://github.com/Relph1119/QuestForMachineLearning-Camp</a></li>
</ul>
<h3 id="深度学习-1"><a href="#深度学习-1" class="headerlink" title="深度学习"></a>深度学习</h3><ul>
<li>花书笔记：<a href="https://discoverml.github.io/simplified-deeplearning/" target="_blank" rel="noopener">https://discoverml.github.io/simplified-deeplearning/</a><ul>
<li>中文版图书：<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="noopener">https://github.com/exacity/deeplearningbook-chinese</a></li>
</ul>
</li>
</ul>
<h3 id="NLP-1"><a href="#NLP-1" class="headerlink" title="NLP"></a>NLP</h3><ul>
<li>斯坦福自然语言处理：<a href="https://zhuanlan.zhihu.com/p/59011576" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59011576</a></li>
<li>宗成庆统计自然语言处理：<ul>
<li><a href="https://github.com/aicourse/ZMC301-CAS-NLP-2019" target="_blank" rel="noopener">https://github.com/aicourse/ZMC301-CAS-NLP-2019</a></li>
<li><a href="http://www.nlpr.ia.ac.cn/cip/ZongReportandLecture/ReportandLectureIndex.htm" target="_blank" rel="noopener">http://www.nlpr.ia.ac.cn/cip/ZongReportandLecture/ReportandLectureIndex.htm</a></li>
</ul>
</li>
</ul>
<h3 id="CV-1"><a href="#CV-1" class="headerlink" title="CV"></a>CV</h3><ul>
<li>CS231n计算机视觉：<ul>
<li><a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21930884</a></li>
<li><a href="https://github.com/mbadry1/CS231n-2017-Summary" target="_blank" rel="noopener">https://github.com/mbadry1/CS231n-2017-Summary</a></li>
</ul>
</li>
</ul>
<h3 id="强化学习-1"><a href="#强化学习-1" class="headerlink" title="强化学习"></a>强化学习</h3><ul>
<li>David Silver强化学习笔记：<a href="https://zhuanlan.zhihu.com/reinforce" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/reinforce</a></li>
</ul>
<h2 id="工具汇总"><a href="#工具汇总" class="headerlink" title="工具汇总"></a>工具汇总</h2><h3 id="NLP-2"><a href="#NLP-2" class="headerlink" title="NLP"></a>NLP</h3><ul>
<li>jialu: <a href="https://github.com/ownthink/Jiagu" target="_blank" rel="noopener">https://github.com/ownthink/Jiagu</a></li>
</ul>
<h2 id="数据集汇总"><a href="#数据集汇总" class="headerlink" title="数据集汇总"></a>数据集汇总</h2><h3 id="NLP-3"><a href="#NLP-3" class="headerlink" title="NLP"></a>NLP</h3><ul>
<li>百度：<a href="http://ai.baidu.com/broad" target="_blank" rel="noopener">http://ai.baidu.com/broad</a></li>
</ul>
<h2 id="前沿追踪类资源"><a href="#前沿追踪类资源" class="headerlink" title="前沿追踪类资源"></a>前沿追踪类资源</h2><h3 id="NLP-4"><a href="#NLP-4" class="headerlink" title="NLP"></a>NLP</h3><ul>
<li><a href="https://github.com/sebastianruder/NLP-progress" target="_blank" rel="noopener">https://github.com/sebastianruder/NLP-progress</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>用GitHub+Hexo搭建个人网站</title>
    <url>/2020/02/01/%E7%94%A8GitHub-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>假期宅在家里，研究了一下用github搭建个人网站，把里面使用到的工具和命令总结一下。相关代码可参考：<a href="https://github.com/majing2019/myblogs" target="_blank" rel="noopener">https://github.com/majing2019/myblogs</a><br><a id="more"></a></p>
<h1 id="安装相关软件"><a href="#安装相关软件" class="headerlink" title="安装相关软件"></a>安装相关软件</h1><blockquote>
<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26625249</a><br><a href="https://zhuanlan.zhihu.com/p/62555815" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62555815</a></p>
</blockquote>
<ul>
<li>npm install -g hexo-cli</li>
<li>hexo init blog</li>
<li>cd ~/blog</li>
<li>export CC=/usr/bin/clang</li>
<li>export CXX=/usr/bin/clang++</li>
<li>npm install</li>
<li>npm install hexo-server —save</li>
<li>hexo server</li>
<li>在<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>访问网站首页</li>
<li>npm install hexo-deployer-git —save</li>
</ul>
<h1 id="建立repository"><a href="#建立repository" class="headerlink" title="建立repository"></a>建立repository</h1><blockquote>
<p>参考：<br><a href="https://help.github.com/en/github/working-with-github-pages" target="_blank" rel="noopener">https://help.github.com/en/github/working-with-github-pages</a><br><a href="https://github.community/t5/GitHub-Pages/404-Error/td-p/14331" target="_blank" rel="noopener">https://github.community/t5/GitHub-Pages/404-Error/td-p/14331</a></p>
</blockquote>
<ul>
<li>创建username.github.io的repository</li>
<li>在Settings-&gt;Github Pages中升级账户</li>
</ul>
<h1 id="修改相关配置"><a href="#修改相关配置" class="headerlink" title="修改相关配置"></a>修改相关配置</h1><ul>
<li>修改_config.yml<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: &lt;repository url&gt; #git@github.com:sufaith&#x2F;sufaith.github.io.git</span><br><span class="line">  branch: [branch] #master</span><br><span class="line">  message: [message]</span><br><span class="line">url: majing2019.github.io</span><br></pre></td></tr></table></figure></li>
<li>在source文件夹下创建CNAME文件，内容为二级域名</li>
<li>在~/blog目录下运行hexo generate</li>
<li>hexo clean &amp;&amp; hexo deploy</li>
<li>访问 <a href="https://majing2019.github.io/archives/" target="_blank" rel="noopener">https://majing2019.github.io/archives/</a></li>
</ul>
<h1 id="绑定域名"><a href="#绑定域名" class="headerlink" title="绑定域名"></a>绑定域名</h1><ul>
<li>登录<a href="https://www.aliyun.com/" target="_blank" rel="noopener">https://www.aliyun.com/</a>注册了一个域名majsunflower.cn</li>
<li>添加一个域名解析<ul>
<li>类型CNAME，主机记录www，记录值majing2019.github.io</li>
<li>类型A，主机记录@，记录值是对应的ip地址，可通过ping majing2019.github.io获得</li>
</ul>
</li>
<li>在github仓库中设置custom domain</li>
<li>在blog下创建source/CNAME文件，并写入majsunflower.cn</li>
</ul>
<h1 id="编写自己的个性化网站"><a href="#编写自己的个性化网站" class="headerlink" title="编写自己的个性化网站"></a>编写自己的个性化网站</h1><blockquote>
<p>参考：<br><a href="https://zhwangart.github.io/2018/11/30/Ocean/" target="_blank" rel="noopener">https://zhwangart.github.io/2018/11/30/Ocean/</a></p>
</blockquote>
<h2 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h2><ul>
<li>在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a>中选择一个主题</li>
<li>git clone <a href="https://github.com/zhwangart/hexo-theme-ocean.git" target="_blank" rel="noopener">https://github.com/zhwangart/hexo-theme-ocean.git</a> themes/ocean</li>
<li>修改_config.yml中theme为ocean</li>
</ul>
<h2 id="配置语言"><a href="#配置语言" class="headerlink" title="配置语言"></a>配置语言</h2><ul>
<li>_config.yml中language改为zh-CN</li>
</ul>
<h2 id="评论功能"><a href="#评论功能" class="headerlink" title="评论功能"></a>评论功能</h2><blockquote>
<p>参考：<br><a href="https://zhwangart.github.io/2018/12/06/Gitalk/" target="_blank" rel="noopener">https://zhwangart.github.io/2018/12/06/Gitalk/</a></p>
</blockquote>
<ul>
<li>在<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">https://github.com/settings/applications/new</a>申请<ul>
<li>后续可在<a href="https://github.com/settings/developers" target="_blank" rel="noopener">https://github.com/settings/developers</a>中修改app相关内容</li>
<li>注意Authorization callback URL在网站绑定域名后需要写域名</li>
</ul>
</li>
<li>填写themes/ocean/_config.yml中gitalk相关字段</li>
</ul>
<h2 id="使用图床"><a href="#使用图床" class="headerlink" title="使用图床"></a>使用图床</h2><blockquote>
<p>参考：<br><a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26625249</a><br><a href="https://blog.csdn.net/qq_36305327/article/details/71578290" target="_blank" rel="noopener">https://blog.csdn.net/qq_36305327/article/details/71578290</a></p>
</blockquote>
<ul>
<li>到<a href="https://www.qiniu.com/" target="_blank" rel="noopener">https://www.qiniu.com/</a>上添加对象存储<a href="https://portal.qiniu.com/kodo/bucket/" target="_blank" rel="noopener">https://portal.qiniu.com/kodo/bucket/</a></li>
<li>在markdown中可直接引用图片<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">![sunflower](http:&#x2F;&#x2F;q503tsu73.bkt.clouddn.com&#x2F;IMG_3012.JPG?e&#x3D;1580527998&amp;token&#x3D;05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:6FFnse-_gOPpSeTWpN-i9hJ1pwQ&#x3D;&amp;attname&#x3D;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="添加关于"><a href="#添加关于" class="headerlink" title="添加关于"></a>添加关于</h2><ul>
<li>hexo new page about</li>
<li>使用markdown编写source/about/index.md</li>
</ul>
<h2 id="添加标签"><a href="#添加标签" class="headerlink" title="添加标签"></a>添加标签</h2><ul>
<li>hexo new page tags // 创建标签页面</li>
<li>修改source/tags/index.md为<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Tags</span><br><span class="line">date: 2019-04-19 17:28:54</span><br><span class="line">type: tags</span><br><span class="line">layout: &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="添加相册"><a href="#添加相册" class="headerlink" title="添加相册"></a>添加相册</h2><ul>
<li>hexo new page gallery</li>
<li>编辑source/gallery/index.md<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Gallery</span><br><span class="line">albums: [</span><br><span class="line">        [&quot;img_url&quot;,&quot;img_caption&quot;],</span><br><span class="line">        [&quot;img_url&quot;,&quot;img_caption&quot;]</span><br><span class="line">        ]</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li>
<li>如果出现相册加载过慢的问题，可以参考<a href="https://zhwangart.github.io/2019/07/02/Ocean-Issues/" target="_blank" rel="noopener">https://zhwangart.github.io/2019/07/02/Ocean-Issues/</a>解决</li>
</ul>
<h2 id="添加分类"><a href="#添加分类" class="headerlink" title="添加分类"></a>添加分类</h2><ul>
<li>hexo new page categories</li>
</ul>
<h2 id="本地搜索"><a href="#本地搜索" class="headerlink" title="本地搜索"></a>本地搜索</h2><blockquote>
<p>参考：<br><a href="https://github.com/zhwangart/gitalk/issues/7#issuecomment-451877736" target="_blank" rel="noopener">https://github.com/zhwangart/gitalk/issues/7#issuecomment-451877736</a></p>
</blockquote>
<ul>
<li>npm install hexo-generator-searchdb —save</li>
<li>在blog/_config.yml中添加配置<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  content: true</span><br></pre></td></tr></table></figure></li>
<li>hexo g</li>
<li><del>修改themes/ocean/layout/_partial/after-footer.ejs中修改如下内容</del><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;% if (theme.local_search.enable)&#123; %&gt;</span><br><span class="line">  &lt;%- js(&#39;&#x2F;js&#x2F;search&#39;) %&gt;</span><br><span class="line">&lt;% &#125; %&gt;</span><br><span class="line"></span><br><span class="line">&lt;%- js(&#39;&#x2F;js&#x2F;ocean&#39;) %&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="用Markdown写文章"><a href="#用Markdown写文章" class="headerlink" title="用Markdown写文章"></a>用Markdown写文章</h2><h3 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a>创建文章</h3><blockquote>
<p>参考：<br><a href="https://chaxiaoniu.oschina.io/2017/07/10/Markdown-Grammar/" target="_blank" rel="noopener">https://chaxiaoniu.oschina.io/2017/07/10/Markdown-Grammar/</a></p>
</blockquote>
<ul>
<li>hexo new “用GitHub+Hexo搭建个人网站”</li>
<li>文章格式如下<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 用GitHub+Hexo搭建个人网站 #文章页面上的显示名称，可以任意修改</span><br><span class="line">date: date  #文章生成时间，一般不改，当然也可以任意修改</span><br><span class="line">tags: [Hexo, Ocean] #文章标签，可空。也可以按照你的习惯写分类名字，注意后面有空格，多个标签可以用[]包含，以&#96;,&#96;隔开</span><br><span class="line">categories: [技术] #分类</span><br><span class="line">---</span><br><span class="line">这里是你博客列表显示的摘要文字</span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line">以下是博客的正文，以上面的格式为分隔线</span><br></pre></td></tr></table></figure></li>
<li>如果不希望显示时有目录，需要添加<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">toc: false</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="添加公式"><a href="#添加公式" class="headerlink" title="添加公式"></a>添加公式</h3><blockquote>
<p>参考：<br><a href="https://blog.csdn.net/Aoman_Hao/article/details/81381507" target="_blank" rel="noopener">https://blog.csdn.net/Aoman_Hao/article/details/81381507</a></p>
</blockquote>
<ul>
<li>npm uninstall hexo-renderer-marked —save</li>
<li>npm install hexo-renderer-kramed —save</li>
<li>修改node_modules/hexo-renderer-kramed/lib/renderer.js<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function formatText(text) &#123;</span><br><span class="line">  &#x2F;&#x2F; Fit kramed&#39;s rule: $$ + \1 + $$</span><br><span class="line">  &#x2F;&#x2F; return text.replace(&#x2F;&#96;\$(.*?)\$&#96;&#x2F;g, &#39;$$$$$1$$$$&#39;);</span><br><span class="line">  return text;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>npm uninstall hexo-math —save</p>
</li>
<li><p>npm install hexo-renderer-mathjax —save</p>
</li>
<li>修改node_modules/hexo-renderer-mathjax/mathjax.html，注释掉最后一行script并改为<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;mathjax&#x2F;2.7.1&#x2F;MathJax.js?config&#x3D;TeX-MML-AM_CHTML&quot;&gt;&lt;&#x2F;script&gt;</span><br></pre></td></tr></table></figure></li>
<li>修改node_modules/kramed/lib/rules/inline.js<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">escape: &#x2F;^\\([&#96;*\[\]()# +\-.!_&gt;])&#x2F;,</span><br><span class="line">em: &#x2F;^\*((?:\*\*|[\s\S])+?)\*(?!\*)&#x2F;,</span><br></pre></td></tr></table></figure></li>
<li>修改themes/ocean/_config.yml增加<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mathjax: true</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="添加文章封面"><a href="#添加文章封面" class="headerlink" title="添加文章封面"></a>添加文章封面</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Post name</span><br><span class="line">photos: [</span><br><span class="line">        [&quot;img_url&quot;],</span><br><span class="line">        [&quot;img_url&quot;]</span><br><span class="line">        ]</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h3 id="添加视频"><a href="#添加视频" class="headerlink" title="添加视频"></a>添加视频</h3><blockquote>
<p>参考：<br><a href="https://blog.csdn.net/u010953692/article/details/79075884" target="_blank" rel="noopener">https://blog.csdn.net/u010953692/article/details/79075884</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;iframe height&#x3D;498 width&#x3D;510 src&#x3D;&quot;http:&#x2F;&#x2F;q503tsu73.bkt.clouddn.com&#x2F;IMG_0018.mp4?e&#x3D;1580557032&amp;token&#x3D;05Ii263bPN3Z-CT3JPRaRfWi5sXIj8pwX6V1bN2j:-rUb7zOxk-WfRrhdJtNdOOGfy58&#x3D;&amp;attname&#x3D;&quot; frameborder&#x3D;0 allowfullscreen&gt;&lt;&#x2F;iframe&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="文章置顶"><a href="#文章置顶" class="headerlink" title="文章置顶"></a>文章置顶</h3><ul>
<li>npm uninstall hexo-generator-index —save</li>
<li>npm install hexo-generator-index-pin-top —save</li>
<li>在需要置顶的文章上加入<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line"> title: 新增文章置顶</span><br><span class="line"> top: ture</span><br><span class="line"> ---</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="同时部署在Github和Coding上"><a href="#同时部署在Github和Coding上" class="headerlink" title="同时部署在Github和Coding上"></a>同时部署在Github和Coding上</h1><blockquote>
<p>参考：<br><a href="https://tomatoro.cn/archives/3de92cb5.html" target="_blank" rel="noopener">https://tomatoro.cn/archives/3de92cb5.html</a></p>
</blockquote>
<ul>
<li><a href="https://coding.net/" target="_blank" rel="noopener">https://coding.net/</a>上创建devops项目</li>
<li>修改blog/_config.yml中的deploy<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: </span><br><span class="line">    github: git@github.com:majing2019&#x2F;majing2019.github.io.git</span><br><span class="line">    coding: git@e.coding.net:majsunflower&#x2F;myblog.git</span><br><span class="line">  branch: master</span><br><span class="line">  message: my blog</span><br></pre></td></tr></table></figure></li>
<li>将id_rsa.pub的公钥复制到个人账户下，ssh -T git@git.coding.net验证是否成功</li>
<li>hexo deploy -g部署到coding上</li>
<li>配置静态页面即可访问：<a href="http://02ss3u.coding-pages.com/" target="_blank" rel="noopener">https://02ss3u.coding-pages.com/</a></li>
<li>在自定义域名里增加：<a href="http://majsunflower.cn/">majsunflower.cn</a></li>
<li>阿里云<a href="https://homenew.console.aliyun.com/" target="_blank" rel="noopener">https://homenew.console.aliyun.com/</a>中修改域名相关配置，区分境内和境外的访问</li>
</ul>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul>
<li><p>部署：hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</p>
</li>
<li><p>本地测试：hexo server</p>
</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Ocean</tag>
      </tags>
  </entry>
</search>
